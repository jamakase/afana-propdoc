{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Базовый алгоритм RAG\n",
    "(обработка нормативной документации по строительству объектов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка документов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from langchain.schema import Document\n",
    "\n",
    "root_folder = \"docs\"\n",
    "\n",
    "# Функция для извлечения номера страницы из имени файла\n",
    "def extract_page_number(file_name):\n",
    "    match = re.search(r'page_(\\d+)', file_name)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    return None\n",
    "\n",
    "# Переменная для хранения всех документов\n",
    "documents = []\n",
    "\n",
    "# Проходим по каждой папке внутри root_folder\n",
    "for folder_name in os.listdir(root_folder):\n",
    "    folder_path = os.path.join(root_folder, folder_name)\n",
    "    \n",
    "    if os.path.isdir(folder_path):        \n",
    "        # Ищем подпапку text_from_pdf в текущей папке\n",
    "        text_from_pdf_folder = os.path.join(folder_path, \"text_from_pdf\")\n",
    "        if os.path.isdir(text_from_pdf_folder):  # Проверяем, существует ли подпапка text_from_pdf\n",
    "            # Собираем все txt файлы и их номера страниц\n",
    "            files_with_pages = []\n",
    "            for file_name in os.listdir(text_from_pdf_folder):\n",
    "                file_path = os.path.join(text_from_pdf_folder, file_name)\n",
    "                \n",
    "                # Проверяем, что это txt-файл\n",
    "                if file_name.endswith(\".txt\"): \n",
    "                    page_number = extract_page_number(file_name)\n",
    "                    if page_number is not None:\n",
    "                        files_with_pages.append((file_name, page_number))\n",
    "            \n",
    "            # Сортируем файлы по номеру страницы\n",
    "            sorted_files = sorted(files_with_pages, key=lambda x: x[1])\n",
    "            \n",
    "            # Проходим по отсортированным файлам\n",
    "            for file_name, page_number in sorted_files:\n",
    "                file_path = os.path.join(text_from_pdf_folder, file_name)\n",
    "                \n",
    "                with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "                    page_content = file.read()\n",
    "\n",
    "                # Создаем объект Document с метаданными\n",
    "                doc = Document(\n",
    "                    page_content=page_content,\n",
    "                    metadata={\n",
    "                        'source': folder_name,  # Название основной папки\n",
    "                        'page': page_number     # Номер страницы\n",
    "                    }\n",
    "                )\n",
    "                \n",
    "                # Добавляем документ в список\n",
    "                documents.append(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разбивка документов на чанки "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "splits = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подгружаем LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "\n",
    "llm = Ollama(model=\"llama3.1\")\n",
    "embedding_model = OllamaEmbeddings(model=\"llama3.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Строим prompt-инструкцию для LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"Вы являетесь помощником в выполнении поиска ответов на вопросы по нормативной документации по строительству объектов. \n",
    "                                          Используйте приведенные ниже фрагменты извлеченного контекста, чтобы ответить на вопрос.\n",
    "                                          Если вы не знаете ответа, просто скажите, что вы не знаете.\n",
    "        Question: {question} \n",
    "        Context: {context} \n",
    "        Answer:\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Индексируем чанки "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "db = FAISS.from_documents(documents=splits, embedding=embedding_model)\n",
    "# сохранение\n",
    "db.save_local(\"path_to_faiss_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "# Загружаем FAISS индекс из файла с разрешением \n",
    "db = FAISS.load_local(\n",
    "    \"path_to_faiss_index\",\n",
    "    embeddings=embedding_model,\n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "\n",
    "# Устанавливаем ретривер для поиска контекста\n",
    "retriever = db.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={'k': 3}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # временное хранение\n",
    "# from langchain.vectorstores import FAISS\n",
    "# db = FAISS.from_documents(documents=splits, embedding=embedding_model)\n",
    "\n",
    "# # устанавливаем ретриевер для поиска контекста\n",
    "# retriever = db.as_retriever(\n",
    "#     search_type=\"similarity\",\n",
    "#     search_kwargs={'k': 3}\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "answer = rag_chain.invoke(\"какой должна быть лестничная клетка?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Лестничная клетка должна быть незадымляемой типа Н1 либо Н2 с входом на каждом этаже через тамбур-шлюз 1-го типа с подпорой воздуха на этаже пожара.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
